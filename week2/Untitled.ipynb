{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f956f4ca-57b2-4254-8e2f-4d81c6da2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\AppData\\Local\\Temp\\ipykernel_16924\\1193264086.py\", line 235, in do_entry\n",
      "    german_translation = translate_text(message)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\AppData\\Local\\Temp\\ipykernel_16924\\1193264086.py\", line 150, in translate_text\n",
      "    response = claude.messages.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py\", line 953, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1336, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1013, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1117, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: Unexpected role \"system\". The Messages API accepts a top-level `system` parameter, not \"system\" as an input message role.'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\AppData\\Local\\Temp\\ipykernel_16924\\1193264086.py\", line 212, in chat\n",
      "    german_reply = translate_text(reply)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\AppData\\Local\\Temp\\ipykernel_16924\\1193264086.py\", line 150, in translate_text\n",
      "    response = claude.messages.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py\", line 953, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1336, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1013, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Startklar\\anaconda3\\envs\\llms\\Lib\\site-packages\\anthropic\\_base_client.py\", line 1117, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: Unexpected role \"system\". The Messages API accepts a top-level `system` parameter, not \"system\" as an input message role.'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import Audio, display\n",
    "import anthropic\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "    \n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "ANTHROPIC_MODEL = \"claude-3-haiku-20240307\"\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\"\n",
    "system_message += \"When booking a flight always check if the desired time is really available.\"\n",
    "\n",
    "translate_system_message = \"You are a language assistant that translates text between English and German. \"\n",
    "translate_system_message += \"Translate the given text from English to German accurately while preserving the meaning and tone. \"\n",
    "translate_system_message += \"Return only the translated text without explanations.\"\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")\n",
    "\n",
    "flight_times = {\"london\": [\"08:00\", \"11:42\", \"13:30\", \"15:47\"], \n",
    "                \"paris\": [\"07:30\", \"10:44\", \"17:30\", \"22:37\"], \n",
    "                \"tokyo\": [\"08:54\", \"14:59\"], \n",
    "                \"berlin\": [\"06:52\", \"09:43\", \"13:56\"]}\n",
    "\n",
    "def get_flight_times(destination_city):\n",
    "    print(f\"Tool get_flight_times called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return flight_times.get(city, \"Unknown\")    \n",
    "\n",
    "def book_flight(destination_city, time):\n",
    "    print(f\"Booking flight to {destination_city} at {time}\")\n",
    "    return f\"Flight to {destination_city.title()} booked for {time}. Confirmation sent!\"\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "flight_times_function = {\n",
    "    \"name\": \"get_flight_times\",\n",
    "    \"description\": \"Get the times of fights to location. Call this whenever you need to know the flight times, for example when a customer want to book a flight to a city, provide him with the time options.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "book_flight_function = {\n",
    "    \"name\": \"book_flight\",\n",
    "    \"description\": \"Book a flight to a city at a specific time.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City to fly to\"\n",
    "            },\n",
    "            \"time\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Departure time in HH:MM\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\", \"time\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": price_function},\n",
    "    {\"type\": \"function\", \"function\": flight_times_function},\n",
    "    {\"type\": \"function\", \"function\": book_flight_function}\n",
    "]\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Handling tool call for function: {function_name}, arguments: {arguments}\")\n",
    "        city = arguments.get(\"destination_city\")\n",
    "\n",
    "        if function_name == \"get_ticket_price\":\n",
    "            result = get_ticket_price(city)\n",
    "        elif function_name == \"get_flight_times\":\n",
    "            result = get_flight_times(city)\n",
    "        elif function_name == \"book_flight\":\n",
    "            time = arguments.get(\"time\")\n",
    "            result = book_flight(city, time)\n",
    "        else:\n",
    "            result = \"Unknown function\"\n",
    "\n",
    "        tool_responses.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": function_name,\n",
    "            \"content\": json.dumps(result)\n",
    "        })\n",
    "    return tool_responses, city\n",
    "\n",
    "def translate_text(text, to_language=\"German\"):\n",
    "    \"\"\"Translate text using Claude Haiku\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    response = claude.messages.create(\n",
    "        model=ANTHROPIC_MODEL,\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": translate_system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate this text to {to_language}: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.content[0].text\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=message)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    # Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))\n",
    "\n",
    "def chat(message, history):\n",
    "    # Translate user message to English if needed (for processing)\n",
    "    # For simplicity, we're assuming input is in English\n",
    "    original_message = message\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    \n",
    "    # Convert history to the format expected by OpenAI API\n",
    "    for h in history:\n",
    "        # Extract only the original message (first part before the translation)\n",
    "        if h[\"role\"] == \"user\" or h[\"role\"] == \"assistant\":\n",
    "            content = h[\"content\"].split(\"\\n\\n**German:** \")[0]\n",
    "            if h[\"role\"] == \"user\":\n",
    "                content = content.replace(\"**English:** \", \"\")\n",
    "            messages.append({\"role\": h[\"role\"], \"content\": content})\n",
    "    \n",
    "    # Add the current user message\n",
    "    messages.append({\"role\": \"user\", \"content\": original_message})\n",
    "    \n",
    "    response = openai.chat.completions.create(model=GPT_MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        assistant_message = response.choices[0].message\n",
    "        \n",
    "        tool_messages, city = handle_tool_call(assistant_message)\n",
    "\n",
    "        # Append assistant tool call message and tool responses\n",
    "        messages.append(assistant_message)\n",
    "        messages.extend(tool_messages)\n",
    "        \n",
    "        # Send updated messages back to OpenAI\n",
    "        response = openai.chat.completions.create(model=GPT_MODEL, messages=messages)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    \n",
    "    # Translate the reply to German\n",
    "    german_reply = translate_text(reply)\n",
    "    \n",
    "    # Format the message to show both English and German\n",
    "    formatted_reply = f\"{reply}\\n\\n**German:** {german_reply}\"\n",
    "    \n",
    "    # Add to history with both original and translated text\n",
    "    history += [{\"role\": \"assistant\", \"content\": formatted_reply}]\n",
    "\n",
    "    # Comment out or delete the next line if you'd rather skip Audio for now\n",
    "    talker(reply)\n",
    "    \n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        # Translate user message to German\n",
    "        german_translation = translate_text(message)\n",
    "        \n",
    "        # Format the message to show both English and German\n",
    "        formatted_message = f\"**English:** {message}\\n\\n**German:** {german_translation}\"\n",
    "        \n",
    "        history += [{\"role\": \"user\", \"content\": formatted_message}]\n",
    "        return \"\", history\n",
    "        \n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "       chat, inputs=[entry, chatbot], outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2db2b-b477-4e07-ab94-f1512e2c6c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
